{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f52175-a7e8-45ab-a965-0d4a1e8e760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90853bde-95df-4827-98af-70410794c502",
   "metadata": {},
   "source": [
    "# Tokenization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d970c20-8f80-4421-bcc3-85a581cf9738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858cb0fc014f44548e41fcf53639168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gdnhy\\.conda\\envs\\XAIenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\gdnhy\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9181e9c080e14ba2bc5b2b83bdd93ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83caea6a66004c5ea70bccb1fd53fc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1200d1f0fe424c2d9eae78c1bea0a335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
      "[101, 1109, 2523, 1110, 25876, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "text = 'The movie is superb'\n",
    "\n",
    "# Tokenize input text\n",
    "text_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokenizer.convert_ids_to_tokens(text_ids))\n",
    "# Output: ['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
    "\n",
    "# Print the ids of the tokens\n",
    "print(text_ids)\n",
    "# Output: [101, 1109, 2523, 1110, 25876, 102]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e541e1-da3d-47dd-a278-7950b4fb0e54",
   "metadata": {},
   "source": [
    "# Minimal Example to Fetch the Embeddings of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb12068-b429-4411-bda5-bedff656d387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c6537d6833479088c02d98e4ecbb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "# Instantiate BERT model\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "embeddings = model.embeddings(torch.tensor([text_ids]))\n",
    "print(embeddings.size())\n",
    "# Output: torch.Size([1, 6, 768]), since there are 6 tokens in text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d6810-edf6-4b1d-a48e-44e034a32a90",
   "metadata": {},
   "source": [
    "# Specify Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea24f09-9fef-469c-8884-794fda046a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask = None):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f1929-401c-40c2-a7a2-4a061380f633",
   "metadata": {},
   "source": [
    "# Load Model's Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da8d59e-4ed4-4ca2-bcdb-93857a9295e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/to/bert_model.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BertClassifier()\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath/to/bert_model.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\gdnhy\\.conda\\envs\\XAIenv\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\gdnhy\\.conda\\envs\\XAIenv\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\gdnhy\\.conda\\envs\\XAIenv\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/to/bert_model.pt'"
     ]
    }
   ],
   "source": [
    "model = BertClassifier()\n",
    "model.load_state_dict(torch.load('path/to/bert_model.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29dd60-b4cc-43d6-b5a7-44f56adca3be",
   "metadata": {},
   "source": [
    "# Define Model Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8bc95b-99f1-4087-a012-8306fe328daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model output\n",
    "def model_output(inputs):\n",
    "  return model(inputs)[0]\n",
    "\n",
    "# Define model input\n",
    "model_input = model.bert.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04dae59-850a-4b11-9684-cdcba55c6e2c",
   "metadata": {},
   "source": [
    "# Instantiate Integrated Gradients Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e805ad-9c5d-40b6-bb9d-890eecde0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "lig = LayerIntegratedGradients(model_output, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86492c38-8201-4d54-aba0-de21e4966a42",
   "metadata": {},
   "source": [
    "# Construct Original and Baseline Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b09b7-a6c2-4e67-bc11-2b25aa3a4a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def construct_input_and_baseline(text):\n",
    "\n",
    "    max_length = 510\n",
    "    baseline_token_id = tokenizer.pad_token_id \n",
    "    sep_token_id = tokenizer.sep_token_id \n",
    "    cls_token_id = tokenizer.cls_token_id \n",
    "\n",
    "    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
    "   \n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "\n",
    "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
    "    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
    "\n",
    "text = 'This movie is superb'\n",
    "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "\n",
    "print(f'original text: {input_ids}')\n",
    "print(f'baseline text: {baseline_input_ids}')\n",
    "\n",
    "# Output: original text: tensor([[  101,  1109,  2523,  1110, 25876,   102]])\n",
    "# Output: baseline text: tensor([[101,   0,   0,   0,   0, 102]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa548b0-e738-45fe-bc0f-0d490427b79b",
   "metadata": {},
   "source": [
    "# Compute Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db56682-41f3-46ec-b331-c81617391fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "print(attributions.size())\n",
    "# Output: torch.Size([1, 6, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864769c7-2378-42a2-8f35-76bd44af63ac",
   "metadata": {},
   "source": [
    "# Compute Attribution for Each Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826a93e2-4b4b-430a-9c20-10cbb5ac08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "attributions_sum = summarize_attributions(attributions)\n",
    "print(attributions_sum.size())\n",
    "# Output: torch.Size([6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123bbd3-536f-48cb-a0fa-c9a6fd9557df",
   "metadata": {},
   "source": [
    "# Visualize the Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2eaaa4-0fa4-4928-a7e2-a727f8e56fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = 1,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c16834-2b58-4d96-b56b-f5908468f64a",
   "metadata": {},
   "source": [
    "# Encapsulate All the Steps Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9ec71-84ca-4734-afd0-b006c3a711df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_text(text, true_class):\n",
    "\n",
    "    input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "    attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "    attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "    score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = true_class,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "    viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57984aee-32e9-418a-a286-f35e0bc67b70",
   "metadata": {},
   "source": [
    "# Interpret Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d530db94-52fa-4c9a-a673-27247eac3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It's a heartfelt film about love, loss, and legacy\"\n",
    "true_class = 1\n",
    "interpret_text(text, true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544cb5c-3afd-45a7-ae82-7f9e692ff223",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A noisy, hideous, and viciously cumbersome movie\"\n",
    "true_class = 0\n",
    "interpret_text(text, true_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
