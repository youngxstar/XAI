{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0f52175-a7e8-45ab-a965-0d4a1e8e760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90853bde-95df-4827-98af-70410794c502",
   "metadata": {},
   "source": [
    "# Tokenization Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d970c20-8f80-4421-bcc3-85a581cf9738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
      "[101, 1109, 2523, 1110, 25876, 102]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "text = 'The movie is superb'\n",
    "\n",
    "# Tokenize input text\n",
    "text_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "# Print the tokens\n",
    "print(tokenizer.convert_ids_to_tokens(text_ids))\n",
    "# Output: ['[CLS]', 'The', 'movie', 'is', 'superb', '[SEP]']\n",
    "\n",
    "# Print the ids of the tokens\n",
    "print(text_ids)\n",
    "# Output: [101, 1109, 2523, 1110, 25876, 102]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e541e1-da3d-47dd-a278-7950b4fb0e54",
   "metadata": {},
   "source": [
    "# Minimal Example to Fetch the Embeddings of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fb12068-b429-4411-bda5-bedff656d387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "# Instantiate BERT model\n",
    "model = BertModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "embeddings = model.embeddings(torch.tensor([text_ids]))\n",
    "print(embeddings.size())\n",
    "# Output: torch.Size([1, 6, 768]), since there are 6 tokens in text_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d6810-edf6-4b1d-a48e-44e034a32a90",
   "metadata": {},
   "source": [
    "# Specify Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ea24f09-9fef-469c-8884-794fda046a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask = None):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f1929-401c-40c2-a7a2-4a061380f633",
   "metadata": {},
   "source": [
    "# Load Model's Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1da8d59e-4ed4-4ca2-bcdb-93857a9295e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier()\n",
    "# model.load_state_dict(torch.load('path/to/bert_model.pt', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29dd60-b4cc-43d6-b5a7-44f56adca3be",
   "metadata": {},
   "source": [
    "# Define Model Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c8bc95b-99f1-4087-a012-8306fe328daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model output\n",
    "def model_output(inputs):\n",
    "  return model(inputs)[0]\n",
    "\n",
    "# Define model input\n",
    "model_input = model.bert.embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04dae59-850a-4b11-9684-cdcba55c6e2c",
   "metadata": {},
   "source": [
    "# Instantiate Integrated Gradients Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8e805ad-9c5d-40b6-bb9d-890eecde0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import LayerIntegratedGradients\n",
    "lig = LayerIntegratedGradients(model_output, model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86492c38-8201-4d54-aba0-de21e4966a42",
   "metadata": {},
   "source": [
    "# Construct Original and Baseline Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "563b09b7-a6c2-4e67-bc11-2b25aa3a4a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: tensor([[  101,  1188,  2523,  1110, 25876,   102]])\n",
      "baseline text: tensor([[101,   0,   0,   0,   0, 102]])\n"
     ]
    }
   ],
   "source": [
    "def construct_input_and_baseline(text):\n",
    "\n",
    "    max_length = 510\n",
    "    baseline_token_id = tokenizer.pad_token_id \n",
    "    sep_token_id = tokenizer.sep_token_id \n",
    "    cls_token_id = tokenizer.cls_token_id \n",
    "\n",
    "    text_ids = tokenizer.encode(text, max_length=max_length, truncation=True, add_special_tokens=False)\n",
    "   \n",
    "    input_ids = [cls_token_id] + text_ids + [sep_token_id]\n",
    "    token_list = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "  \n",
    "\n",
    "    baseline_input_ids = [cls_token_id] + [baseline_token_id] * len(text_ids) + [sep_token_id]\n",
    "    return torch.tensor([input_ids], device='cpu'), torch.tensor([baseline_input_ids], device='cpu'), token_list\n",
    "\n",
    "text = 'This movie is superb'\n",
    "input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "\n",
    "print(f'original text: {input_ids}')\n",
    "print(f'baseline text: {baseline_input_ids}')\n",
    "\n",
    "# Output: original text: tensor([[  101,  1109,  2523,  1110, 25876,   102]])\n",
    "# Output: baseline text: tensor([[101,   0,   0,   0,   0, 102]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfae05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1aa548b0-e738-45fe-bc0f-0d490427b79b",
   "metadata": {},
   "source": [
    "# Compute Attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db56682-41f3-46ec-b331-c81617391fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 768])\n"
     ]
    }
   ],
   "source": [
    "attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "print(attributions.size())\n",
    "# Output: torch.Size([1, 6, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864769c7-2378-42a2-8f35-76bd44af63ac",
   "metadata": {},
   "source": [
    "# Compute Attribution for Each Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826a93e2-4b4b-430a-9c20-10cbb5ac08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "def summarize_attributions(attributions):\n",
    "\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    \n",
    "    return attributions\n",
    "\n",
    "attributions_sum = summarize_attributions(attributions)\n",
    "print(attributions_sum.size())\n",
    "# Output: torch.Size([6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123bbd3-536f-48cb-a0fa-c9a6fd9557df",
   "metadata": {},
   "source": [
    "# Visualize the Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2eaaa4-0fa4-4928-a7e2-a727f8e56fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.41)</b></text></td><td><text style=\"padding-right:2em\"><b>This movie is superb</b></text></td><td><text style=\"padding-right:2em\"><b>-1.73</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> superb                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.41)</b></text></td><td><text style=\"padding-right:2em\"><b>This movie is superb</b></text></td><td><text style=\"padding-right:2em\"><b>-1.73</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> superb                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from captum.attr import visualization as viz\n",
    "\n",
    "score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = 1,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c16834-2b58-4d96-b56b-f5908468f64a",
   "metadata": {},
   "source": [
    "# Encapsulate All the Steps Above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6c9ec71-84ca-4734-afd0-b006c3a711df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_text(text, true_class):\n",
    "\n",
    "    input_ids, baseline_input_ids, all_tokens = construct_input_and_baseline(text)\n",
    "    attributions, delta = lig.attribute(inputs= input_ids,\n",
    "                                    baselines= baseline_input_ids,\n",
    "                                    return_convergence_delta=True\n",
    "                                    )\n",
    "    attributions_sum = summarize_attributions(attributions)\n",
    "\n",
    "    score_vis = viz.VisualizationDataRecord(\n",
    "                        word_attributions = attributions_sum,\n",
    "                        pred_prob = torch.max(model(input_ids)[0]),\n",
    "                        pred_class = torch.argmax(model(input_ids)[0]).numpy(),\n",
    "                        true_class = true_class,\n",
    "                        attr_class = text,\n",
    "                        attr_score = attributions_sum.sum(),       \n",
    "                        raw_input_ids = all_tokens,\n",
    "                        convergence_score = delta)\n",
    "\n",
    "    viz.visualize_text([score_vis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57984aee-32e9-418a-a286-f35e0bc67b70",
   "metadata": {},
   "source": [
    "# Interpret Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d530db94-52fa-4c9a-a673-27247eac3b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.35)</b></text></td><td><text style=\"padding-right:2em\"><b>It's a heartfelt film about love, loss, and legacy</b></text></td><td><text style=\"padding-right:2em\"><b>0.00</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> '                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> s                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> heart                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##fe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lt                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> film                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> about                    </font></mark><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> love                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> loss                    </font></mark><mark style=\"background-color: hsl(0, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 61%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> legacy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"It's a heartfelt film about love, loss, and legacy\"\n",
    "true_class = 1\n",
    "interpret_text(text, true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8544cb5c-3afd-45a7-ae82-7f9e692ff223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.40)</b></text></td><td><text style=\"padding-right:2em\"><b>A noisy, hideous, and viciously cumbersome movie</b></text></td><td><text style=\"padding-right:2em\"><b>2.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> A                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> noisy                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> hideous                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ,                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> and                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> vicious                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ly                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> cum                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##bers                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ome                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"A noisy, hideous, and viciously cumbersome movie\"\n",
    "true_class = 0\n",
    "interpret_text(text, true_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
